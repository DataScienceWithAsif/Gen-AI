{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344eea72-bb93-491a-8aaa-138f19297318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e048fff8-680d-4646-b0be-8541e343a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82cd949c-3e63-4c55-9df2-82e86826e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFDirectoryLoader(\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ca0e6d-74cc-4f88-a197-65c854d08cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8bc1ad7-4ee0-4dc3-b471-1bedf3d6cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598d1392-4e7c-4224-b080-24752b28b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks=text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e4b211-9003-44e0-ba0a-e44a7376e233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ee9d0e-3d8e-4147-b3f6-dcc8d6bce1ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones∗\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez∗ †\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b74d5b-5058-4fe4-ac49-56ee76db31b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Łukasz Kaiser∗\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin∗ ‡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f505ce8-6dbe-4a91-b9a3-1b0bd05709ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ccb1c31-39bd-4c28-b25c-d733ee0ff474",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\n",
      "sentence. We give two such examples above, from two different heads from the encoder self-attention\n",
      "at layer 5 of 6. The heads clearly learned to perform different tasks.\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[89].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24c1fc1e-f853-4453-ab27-493743093758",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting openai api key in environment\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be60c433-5df9-4b25-abf4-4dba10762545",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "740e129c-847a-4b09-88ee-23584155b694",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed51aa1a-7d21-482d-823f-1fea39f68756",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.016759871364141955,\n",
       " -0.012100923445690675,\n",
       " 0.006689139025905976,\n",
       " -0.025966693940268237,\n",
       " -0.01614279376091156,\n",
       " 0.017648466763578393,\n",
       " -0.0110950847731302,\n",
       " -0.00997200096480045,\n",
       " -0.018203836792750276,\n",
       " -0.01036076017148529,\n",
       " 0.027842616112576643,\n",
       " 0.00172319376118849,\n",
       " -0.007386438431189944,\n",
       " -0.011613431002925067,\n",
       " 0.007225998086711969,\n",
       " -0.015377614440914773,\n",
       " 0.028385644254407774,\n",
       " -0.011847921274463618,\n",
       " 0.013995357517687589,\n",
       " -0.02059810519485355,\n",
       " 0.002542366393579187,\n",
       " 0.006374428349297784,\n",
       " 0.0010374645260404945,\n",
       " -0.008262690546301703,\n",
       " -0.015858935940010005,\n",
       " -0.007762856681856653,\n",
       " 0.025053416628795535,\n",
       " -0.01238478033526961,\n",
       " 0.02231358469437743,\n",
       " -0.025115124202854052,\n",
       " 0.005624677319799555,\n",
       " 0.00768263674244832,\n",
       " -0.013131445892932652,\n",
       " 0.004097406014286406,\n",
       " 0.008811891494448446,\n",
       " -0.022288902782341167,\n",
       " 0.004048039861907331,\n",
       " -0.010403955845855298,\n",
       " 0.02031424923659723,\n",
       " -0.0063003788878985174,\n",
       " 0.027052753949220975,\n",
       " 0.0012503568439787133,\n",
       " -0.00526985690631785,\n",
       " -0.014180481171185755,\n",
       " -0.04149240823530416,\n",
       " 0.014513703747482455,\n",
       " -0.010070733269558598,\n",
       " -0.015254198361475122,\n",
       " -0.017882957035116945,\n",
       " 0.03588932921835092,\n",
       " 0.020610447082194297,\n",
       " 0.015069074707976955,\n",
       " -0.029965368581119114,\n",
       " -0.021832264126604817,\n",
       " 0.0018543231709701278,\n",
       " -0.004853327987455011,\n",
       " -0.004939719336195028,\n",
       " 0.01911711410422298,\n",
       " -0.00986092584137893,\n",
       " -0.02564581231998967,\n",
       " -0.0014971885371967055,\n",
       " 0.006343574562268526,\n",
       " -0.0011747646466618528,\n",
       " 0.015180148900075855,\n",
       " 0.011002522480719807,\n",
       " -0.010385443946166792,\n",
       " 0.02567049609467117,\n",
       " 0.008855087168818455,\n",
       " -0.010064562325888224,\n",
       " 0.006905116466433402,\n",
       " -0.012557562101427026,\n",
       " 0.007701149107798137,\n",
       " -0.008873599068506962,\n",
       " -0.0034001066090024383,\n",
       " 0.01237243844792886,\n",
       " -0.013847257663566436,\n",
       " -0.022461683617175966,\n",
       " 0.01137277071903876,\n",
       " -0.004859498931125386,\n",
       " -0.0054364681944662,\n",
       " 0.020918986815132115,\n",
       " -0.04107279524159006,\n",
       " -0.010292881653756398,\n",
       " 0.011459161136456158,\n",
       " 0.01836427760288956,\n",
       " -0.0013784007819251636,\n",
       " -0.011989849253591775,\n",
       " 0.012736515742577436,\n",
       " -0.010002854751829706,\n",
       " -0.022831930924172298,\n",
       " -0.005815971916968097,\n",
       " 0.006719992812935235,\n",
       " 6.546824751617951e-05,\n",
       " 0.02868184210000484,\n",
       " -0.014526045634823206,\n",
       " 0.0026195013268136415,\n",
       " 0.012514367358379635,\n",
       " 0.019191163565622244,\n",
       " -0.004979829538729849,\n",
       " -0.02217782765891965,\n",
       " -0.02062278896953505,\n",
       " -0.000572726681359767,\n",
       " -0.010786545040192382,\n",
       " -0.004433714528079603,\n",
       " 0.0015234143493038366,\n",
       " 0.0023865540240233392,\n",
       " -0.011767700869393976,\n",
       " -0.005001427375914853,\n",
       " 0.012329242773558851,\n",
       " -0.015982352950772275,\n",
       " -0.013180812510973037,\n",
       " 0.011212329908899475,\n",
       " 0.005985668676951634,\n",
       " -0.018685159223168126,\n",
       " 0.001846609607797486,\n",
       " -0.005852996647667729,\n",
       " -0.0037456710726398892,\n",
       " -0.009749851649280031,\n",
       " -0.011076571942119074,\n",
       " -0.005090903730828749,\n",
       " 0.0106507880047346,\n",
       " 0.01355105981796937,\n",
       " -0.001358345680657753,\n",
       " -0.025398982023755606,\n",
       " 0.009058723653327747,\n",
       " 0.006454648754367426,\n",
       " -0.02878057533608561,\n",
       " -0.002639556428081052,\n",
       " 0.0016260038431019524,\n",
       " -0.003816635062203968,\n",
       " 0.027052753949220975,\n",
       " 0.00945982474735334,\n",
       " -0.007454317414580145,\n",
       " -0.0028632477810271004,\n",
       " -0.006010351985971826,\n",
       " 0.019080090304845962,\n",
       " -0.023263887667872386,\n",
       " 0.02317749631913237,\n",
       " -0.02006741707771793,\n",
       " -0.015673813217834457,\n",
       " 0.000920219390271219,\n",
       " 0.021141135199329916,\n",
       " 0.028755893424049345,\n",
       " -0.01669816379008344,\n",
       " -0.010336077328126407,\n",
       " 0.0017725601463982193,\n",
       " 0.02317749631913237,\n",
       " -0.012353926548240352,\n",
       " -0.006090571925380158,\n",
       " -0.01659943241664791,\n",
       " 0.02286895658619455,\n",
       " -0.00784924756493536,\n",
       " 0.028064764496774443,\n",
       " 0.03722221952353772,\n",
       " 0.002974321973126,\n",
       " 0.01790763894715321,\n",
       " -0.007676465798777945,\n",
       " 0.02687997125174094,\n",
       " 0.001207932653982829,\n",
       " -0.00875018392038993,\n",
       " -0.02999005049315538,\n",
       " -0.00930555488088443,\n",
       " 0.021264550347446946,\n",
       " 0.002798454269472087,\n",
       " -0.016661139990706425,\n",
       " 0.027817932337895142,\n",
       " 0.0447999520862349,\n",
       " -0.01070632463512274,\n",
       " -0.012724173855236685,\n",
       " -0.00309928055565259,\n",
       " 0.0010320650667442434,\n",
       " -0.010576738543335334,\n",
       " -0.04536766400274753,\n",
       " 0.007583903972028861,\n",
       " -0.015278882136156623,\n",
       " -0.005871509013017547,\n",
       " 0.008009688375074644,\n",
       " -0.007670294855107569,\n",
       " -0.03203875350029858,\n",
       " -0.01647601540588564,\n",
       " -0.03448238758911962,\n",
       " 0.01743865840407611,\n",
       " 0.027200852872019506,\n",
       " 0.02507810040347704,\n",
       " 0.005454980559816016,\n",
       " 0.00327977623422863,\n",
       " 0.009879438672390056,\n",
       " 0.008861258112488831,\n",
       " 0.040159517930117364,\n",
       " -0.020178490338494212,\n",
       " 0.019906976267578647,\n",
       " 0.02833627856769001,\n",
       " 0.014785218749720639,\n",
       " -0.016747531339446443,\n",
       " -0.6792808495382379,\n",
       " -0.027891981799294408,\n",
       " 0.01758675918951988,\n",
       " -0.0073432427568199355,\n",
       " 0.01580957025329224,\n",
       " 0.02485595201927924,\n",
       " 0.014637119826922106,\n",
       " 0.02979258588363908,\n",
       " -0.01861110976176886,\n",
       " 0.02589264447886897,\n",
       " -0.005677128944013817,\n",
       " 0.01656240675462566,\n",
       " 0.0012117893773614863,\n",
       " -0.00807139688045578,\n",
       " 0.0010143239529378963,\n",
       " -0.031742555654701514,\n",
       " -0.009052552709657373,\n",
       " -0.003761097966154518,\n",
       " -0.019018382730787445,\n",
       " -0.00033958642016443825,\n",
       " -0.01647601540588564,\n",
       " 0.0057079827310430745,\n",
       " -0.024152481204663585,\n",
       " -0.002991291602558223,\n",
       " 0.01656240675462566,\n",
       " 0.002471402404015108,\n",
       " 0.031495725358467445,\n",
       " -0.01500736713391844,\n",
       " -0.025917328253550472,\n",
       " 0.026509723944744604,\n",
       " -0.02284427281151305,\n",
       " 0.010552054768653832,\n",
       " 0.006966824506153227,\n",
       " -0.020931328702472867,\n",
       " 0.05346374465788481,\n",
       " -0.0006649028823371156,\n",
       " -0.007306218026120302,\n",
       " 0.022881298473535303,\n",
       " -0.0035451202927964387,\n",
       " 0.03364316160169142,\n",
       " -0.00661508956450671,\n",
       " -0.008262690546301703,\n",
       " 0.011743018026035093,\n",
       " -0.03159445673190298,\n",
       " 0.00992880529043044,\n",
       " -0.001567381275217315,\n",
       " 0.00968197313155114,\n",
       " 0.0008191726905983606,\n",
       " 0.013649793054050138,\n",
       " -0.0009595582248472432,\n",
       " 0.003267434579718534,\n",
       " 0.011780042756734726,\n",
       " -0.009657290288192257,\n",
       " 0.011459161136456158,\n",
       " 0.0011894202886330123,\n",
       " 0.0031116219773320315,\n",
       " 0.028903992346847877,\n",
       " 0.005374760154746375,\n",
       " 0.009749851649280031,\n",
       " 0.00359140120617098,\n",
       " -0.006284951994383888,\n",
       " 0.019339262488420775,\n",
       " -0.013933649012306454,\n",
       " -0.000447768127937009,\n",
       " -0.014291555363284655,\n",
       " 0.005819057388803284,\n",
       " -0.004483080680458678,\n",
       " 0.008083737836473912,\n",
       " 0.0053099666431913614,\n",
       " -0.005060049943799491,\n",
       " 0.007337072278810869,\n",
       " 0.0010081532420981756,\n",
       " -0.010021366651518215,\n",
       " -0.005056964471964303,\n",
       " 0.014822243480420272,\n",
       " 0.02244934359248045,\n",
       " 0.025744545556070437,\n",
       " -0.0037672686769942387,\n",
       " 0.01097166869369055,\n",
       " 0.0033846797154878094,\n",
       " 0.024004382281865053,\n",
       " -0.0009965829555468764,\n",
       " -0.026805921790341674,\n",
       " 0.002613330615973921,\n",
       " 0.00986092584137893,\n",
       " -0.02858311072656931,\n",
       " -0.02478190255787997,\n",
       " 0.016994361635680508,\n",
       " 0.02364647686220947,\n",
       " 0.010064562325888224,\n",
       " 0.02858311072656931,\n",
       " 0.026361625021946073,\n",
       " 0.008497180817840254,\n",
       " -0.03364316160169142,\n",
       " 0.006112169762565163,\n",
       " -0.011335745988339125,\n",
       " -0.014945659559859922,\n",
       " 0.016525381092603406,\n",
       " 0.0063003788878985174,\n",
       " -0.0031964703573238,\n",
       " -0.0027845701118750523,\n",
       " -0.01647601540588564,\n",
       " 0.026805921790341674,\n",
       " 0.017413976492039844,\n",
       " 0.007176631468671585,\n",
       " -0.0032365805598586215,\n",
       " -0.016204501334970076,\n",
       " 0.02140030738290473,\n",
       " 0.018907307607365927,\n",
       " 0.0028046252131424627,\n",
       " 0.012921639396075603,\n",
       " 0.0017741027659004859,\n",
       " -0.0005040766210490878,\n",
       " -0.004609581766072206,\n",
       " 0.024658485547117703,\n",
       " -0.02542366393579187,\n",
       " 0.0127858814292952,\n",
       " 0.019080090304845962,\n",
       " 0.03203875350029858,\n",
       " -0.019684827883380846,\n",
       " 0.01355105981796937,\n",
       " -0.01199602019726215,\n",
       " 0.014958000515878055,\n",
       " 0.006411453079997418,\n",
       " -0.009465995691023714,\n",
       " 0.017327585143299826,\n",
       " -0.023806917672348753,\n",
       " 0.014402629555383555,\n",
       " -0.03467985406128115,\n",
       " 0.01736460894267684,\n",
       " 0.014501361860141703,\n",
       " -0.0032026413009941758,\n",
       " 0.005140269883207824,\n",
       " -0.020585763307512796,\n",
       " 0.02902740749496491,\n",
       " -0.0005445724493556435,\n",
       " 0.01024968597938639,\n",
       " -0.00226776615233647,\n",
       " 0.01995634195429641,\n",
       " -0.004334981757660144,\n",
       " -0.0008623682485530419,\n",
       " -0.013908966168947571,\n",
       " 0.006972995449823602,\n",
       " 0.01501970902125919,\n",
       " 0.007608586815387744,\n",
       " -0.0015419267146536532,\n",
       " -0.0011585662687730997,\n",
       " -0.012255193312159584,\n",
       " -0.009718997862250773,\n",
       " -0.002721319336237633,\n",
       " 0.0007026989809955458,\n",
       " -0.005649360628819746,\n",
       " -0.01872218488519038,\n",
       " 0.018623451649109612,\n",
       " 0.024251214440744354,\n",
       " -0.015550397138394807,\n",
       " -0.00789244323930537,\n",
       " -0.02284427281151305,\n",
       " 0.006368257871288718,\n",
       " -0.011601090046906935,\n",
       " 0.012211998569112193,\n",
       " 0.01815447110603251,\n",
       " -0.012242852356141452,\n",
       " -0.003434045867866884,\n",
       " 0.003936965669808431,\n",
       " -0.03277924811429125,\n",
       " -0.0010660044420240163,\n",
       " 0.029002723720283407,\n",
       " -0.0069976787588437945,\n",
       " -0.026386308796627574,\n",
       " 0.00515878224855764,\n",
       " -0.018228520567431777,\n",
       " -0.015562738094412939,\n",
       " -0.0041807118911912355,\n",
       " 0.004825559672260941,\n",
       " -0.00672616375660561,\n",
       " -0.01238478033526961,\n",
       " -0.011601090046906935,\n",
       " 0.02019083222583496,\n",
       " -0.01356340170531012,\n",
       " 0.007651782489757753,\n",
       " -0.0041807118911912355,\n",
       " -0.018783892459248896,\n",
       " 0.022153143884238148,\n",
       " 0.02845969371580704,\n",
       " -0.008330569995353213,\n",
       " 0.030533080497631745,\n",
       " 0.044972734783714934,\n",
       " -0.014661802670280989,\n",
       " 0.01622918324700634,\n",
       " 0.024164823092004337,\n",
       " 0.011588748159566184,\n",
       " -0.025127466090194804,\n",
       " -0.0050168542694294825,\n",
       " -0.005384016570251938,\n",
       " -0.018401303264911812,\n",
       " -0.01791998083449396,\n",
       " -0.0020903559455956178,\n",
       " 0.021881629813322583,\n",
       " 0.022634466314655998,\n",
       " 0.0221901695462604,\n",
       " 0.005279112856162104,\n",
       " 0.03260646541681121,\n",
       " -0.014155797396504254,\n",
       " 0.0024852865616121433,\n",
       " -0.02444867905026065,\n",
       " 0.0025130551096368683,\n",
       " -0.012847589934676336,\n",
       " 0.014057065091746104,\n",
       " 0.03667919138170659,\n",
       " 0.0015828082851472712,\n",
       " 0.007164290046992144,\n",
       " 0.0010683184294850796,\n",
       " -0.0011716791748266652,\n",
       " 0.004689802171141849,\n",
       " 0.007830735665246854,\n",
       " -0.010508859094283823,\n",
       " 0.002167490878830072,\n",
       " -0.019931660042260147,\n",
       " 0.013279544815731185,\n",
       " 0.01928989680170301,\n",
       " 0.0049181214990100235,\n",
       " -0.007084069641922502,\n",
       " -0.01911711410422298,\n",
       " -0.0038536597929036014,\n",
       " 0.020252539799893478,\n",
       " 0.012971006014115986,\n",
       " 0.032088121049661585,\n",
       " 0.002605617169216606,\n",
       " -0.01321783724167267,\n",
       " -0.033692525425763946,\n",
       " 0.012390951278939985,\n",
       " 0.015377614440914773,\n",
       " 0.0015357560038139326,\n",
       " -0.004125174795141785,\n",
       " 0.005346991373890995,\n",
       " 0.01704372918504351,\n",
       " 0.0011477673501805975,\n",
       " 0.03186597080281855,\n",
       " -0.0036963046874301598,\n",
       " -0.01289695655271672,\n",
       " 0.01636494214510936,\n",
       " 0.031742555654701514,\n",
       " -0.022251877120318914,\n",
       " 0.024720194983821456,\n",
       " 0.0028478206546818166,\n",
       " 0.020005709503659413,\n",
       " 0.0011307977207483746,\n",
       " 0.013378278051811953,\n",
       " 0.01979590114415713,\n",
       " -0.013489352243910853,\n",
       " -0.005677128944013817,\n",
       " -0.013588084548669003,\n",
       " -0.008947648529906229,\n",
       " 0.008379935682070978,\n",
       " -0.017549733527497627,\n",
       " -0.003434045867866884,\n",
       " -0.0004936633864359841,\n",
       " 0.005152611770548574,\n",
       " 0.020363614923314996,\n",
       " 0.008441644187452113,\n",
       " 0.02311578874507385,\n",
       " 0.004637350546927586,\n",
       " -0.004409031219059411,\n",
       " 0.009984341920818582,\n",
       " 0.004421372640738852,\n",
       " 0.00028154240735273013,\n",
       " -0.02564581231998967,\n",
       " -0.011490015854808034,\n",
       " -0.006794042274334501,\n",
       " -0.026188842324466038,\n",
       " -0.008737842033049179,\n",
       " 0.026090110951030508,\n",
       " -0.0001377822255956066,\n",
       " 0.02845969371580704,\n",
       " 0.005152611770548574,\n",
       " -0.0009456739508348806,\n",
       " -0.03048371481091398,\n",
       " 0.0009279328952361972,\n",
       " 0.008083737836473912,\n",
       " -0.01773485811231841,\n",
       " -0.026164160412429773,\n",
       " 0.00823800770294282,\n",
       " 0.015858935940010005,\n",
       " 0.007553049719338294,\n",
       " -0.011440649236767651,\n",
       " -0.033840624348562484,\n",
       " 0.011415965462086149,\n",
       " -0.00818247107255468,\n",
       " 0.014624777939581356,\n",
       " -0.01605640241217154,\n",
       " 0.016759871364141955,\n",
       " -0.011348086944357258,\n",
       " -0.013736183471467536,\n",
       " 0.015093758482658457,\n",
       " 0.01334125332111232,\n",
       " 0.04104811146690856,\n",
       " 0.005124842989693195,\n",
       " -0.00023024768955750397,\n",
       " 0.014711169288321372,\n",
       " -0.008602084997591396,\n",
       " -0.006183133752129242,\n",
       " -0.0013460041425629845,\n",
       " -0.03364316160169142,\n",
       " -0.011601090046906935,\n",
       " -0.006176963274120176,\n",
       " 0.0035482055318009718,\n",
       " -0.01894433326938818,\n",
       " -0.015513372407695174,\n",
       " -0.014217505901885388,\n",
       " 0.011237012752258357,\n",
       " 0.008176300128884303,\n",
       " -0.019684827883380846,\n",
       " -0.01715480244581979,\n",
       " -0.0009904121282918285,\n",
       " 0.00028848454435891134,\n",
       " -0.010515030037954199,\n",
       " 0.00817012918521393,\n",
       " 0.038407010905925985,\n",
       " -0.02734895179481804,\n",
       " -0.010212661248686757,\n",
       " -0.007861589452276111,\n",
       " -0.02306642119571085,\n",
       " -0.010225003136027507,\n",
       " 0.0673356833021649,\n",
       " 0.0019237445410319404,\n",
       " 0.010046050426199715,\n",
       " 0.013921308056288322,\n",
       " 0.004550959198187569,\n",
       " 0.004905780077330582,\n",
       " -0.0014640205298757294,\n",
       " -0.024066089855923567,\n",
       " -0.013908966168947571,\n",
       " 0.0031393905253567565,\n",
       " -0.004800876363240748,\n",
       " -0.02063512899423056,\n",
       " -0.02653440771942611,\n",
       " 0.006284951994383888,\n",
       " -0.0004242419872703397,\n",
       " -0.0014894749740240636,\n",
       " -0.0005287597554462888,\n",
       " -0.025818595017469703,\n",
       " -0.006466990641708177,\n",
       " 0.011588748159566184,\n",
       " -0.009552387039763731,\n",
       " 0.009398117173294822,\n",
       " 0.015476347676995541,\n",
       " 0.02397969850718355,\n",
       " 0.006763188487305244,\n",
       " 0.013538718861951238,\n",
       " 0.003656194484895339,\n",
       " 0.004504678517643682,\n",
       " -0.0005060049827384164,\n",
       " -0.0224123179304582,\n",
       " -0.013526376974610487,\n",
       " -0.005306881637017483,\n",
       " 0.016426649719167876,\n",
       " 0.0023371876388136098,\n",
       " 0.001089144898711287,\n",
       " 0.0224370017051397,\n",
       " 0.010669299904423108,\n",
       " 0.011298721257639492,\n",
       " 0.00834908189504172,\n",
       " -0.007077898698252127,\n",
       " 0.024485704712282903,\n",
       " 0.030508396722950245,\n",
       " 0.0015573537245836095,\n",
       " -0.012304559930199969,\n",
       " 0.014649460782940238,\n",
       " -0.008953819473576605,\n",
       " -0.024658485547117703,\n",
       " -0.010132440843617115,\n",
       " -0.008922965686547346,\n",
       " 0.0009279328952361972,\n",
       " 0.027497050717616572,\n",
       " 0.017167144333160543,\n",
       " -0.024337605789484372,\n",
       " -0.00823800770294282,\n",
       " -0.006152279965099984,\n",
       " 0.011317233157327999,\n",
       " -0.019154139766245228,\n",
       " -0.015143124169376222,\n",
       " -0.005627762791634742,\n",
       " -0.00902786893497587,\n",
       " -0.00812693351084392,\n",
       " -0.008151616354202803,\n",
       " -0.013538718861951238,\n",
       " -0.008799549607107696,\n",
       " -0.012711831967895935,\n",
       " -0.05129162463997934,\n",
       " -0.0020379040885507007,\n",
       " -0.005260600490812287,\n",
       " 0.002420493282887785,\n",
       " -0.00711492342895176,\n",
       " -0.009225334475814789,\n",
       " -0.032088121049661585,\n",
       " -0.018401303264911812,\n",
       " -0.0031471042049447256,\n",
       " 0.019302238689043762,\n",
       " 0.014168139283845005,\n",
       " 0.012946322239434486,\n",
       " -0.022967689822275317,\n",
       " 0.023671158774245735,\n",
       " 0.027817932337895142,\n",
       " 0.0022739370960068454,\n",
       " -0.025966693940268237,\n",
       " 0.025349614474392605,\n",
       " -0.0012318444786288967,\n",
       " -0.005010683325759107,\n",
       " 0.012415634122298867,\n",
       " -0.00504770805645874,\n",
       " 0.020450006272055014,\n",
       " 0.0006490902466354245,\n",
       " 0.016994361635680508,\n",
       " 0.025238541213616322,\n",
       " 0.00817012918521393,\n",
       " 0.023695842548927235,\n",
       " -0.01289695655271672,\n",
       " 0.012761198585936318,\n",
       " 0.01058290855568309,\n",
       " 0.007201314777691778,\n",
       " 0.00277377119328255,\n",
       " -0.029619803186159043,\n",
       " 0.013958332786987954,\n",
       " -0.0037364148899649806,\n",
       " -0.03137231021035042,\n",
       " 0.004708314536491665,\n",
       " -0.03216216864841561,\n",
       " -0.009046381765986997,\n",
       " 0.023584769288150953,\n",
       " -0.011854092218133992,\n",
       " 0.025621130407953406,\n",
       " -0.010613763274034967,\n",
       " -0.011804725600093609,\n",
       " 0.01804339784525623,\n",
       " -0.04334364663293107,\n",
       " 0.023745208235645,\n",
       " -0.00791712701398687,\n",
       " 0.018672817335827378,\n",
       " 0.00992880529043044,\n",
       " 0.006466990641708177,\n",
       " 0.03551908004870935,\n",
       " -0.01624152513434709,\n",
       " -0.020018051391000165,\n",
       " 0.007781369047206469,\n",
       " -0.059239606372318086,\n",
       " 0.02163479765444328,\n",
       " -0.01074952030949275,\n",
       " -0.01060759233036459,\n",
       " 0.00857123027923952,\n",
       " -0.009040210822316621,\n",
       " -0.01569849512987072,\n",
       " -0.0067508470656258025,\n",
       " -0.016118109986230058,\n",
       " -0.008855087168818455,\n",
       " 0.014809901593079522,\n",
       " -0.0024143225720480643,\n",
       " -0.021930995500040348,\n",
       " -0.014686485513639871,\n",
       " -0.018450668951629577,\n",
       " 0.0027151486253979124,\n",
       " 0.02873120964936784,\n",
       " 0.0029619803186159044,\n",
       " -0.009058723653327747,\n",
       " -0.02831159479300851,\n",
       " -0.008268861489972077,\n",
       " -0.00800351743140427,\n",
       " -0.038555109828724524,\n",
       " -0.035148834604358255,\n",
       " -0.03862916115276903,\n",
       " -0.00997200096480045,\n",
       " 0.00981773109833154,\n",
       " -0.020388298697996497,\n",
       " 0.005476578397001021,\n",
       " -0.006062803610186089,\n",
       " 0.006880433623074519,\n",
       " -0.03280393188897275,\n",
       " -0.0017201084057686298,\n",
       " -0.004628094131422024,\n",
       " -0.028410328029089275,\n",
       " -0.0038660014474136972,\n",
       " -0.000827657505314472,\n",
       " 0.01501970902125919,\n",
       " 0.011150621403518341,\n",
       " 0.038999406597120125,\n",
       " 0.01768549056295541,\n",
       " 0.028064764496774443,\n",
       " 0.0027537160920151397,\n",
       " -0.02119050088604768,\n",
       " -0.009441311916342213,\n",
       " -0.008367594726052845,\n",
       " -0.013242520085031552,\n",
       " -0.018537060300369595,\n",
       " 0.023695842548927235,\n",
       " 0.009651119344521881,\n",
       " 0.024386971476202137,\n",
       " 0.013193154398313787,\n",
       " 0.02031424923659723,\n",
       " 0.0024482618309125096,\n",
       " -0.011705993295335459,\n",
       " 0.008416960412770612,\n",
       " -0.005637018741478996,\n",
       " -0.02284427281151305,\n",
       " -0.020227857887857213,\n",
       " 0.014439654286083188,\n",
       " -0.005421041300951571,\n",
       " -0.024177164979345085,\n",
       " 0.015476347676995541,\n",
       " 0.008022030262415396,\n",
       " -0.03487731680815222,\n",
       " -0.010428638689214181,\n",
       " 0.006787871796325435,\n",
       " 0.02070917845562983,\n",
       " -0.0077381738384977704,\n",
       " 0.020178490338494212,\n",
       " -0.016870946487563473,\n",
       " -0.018969015181424444,\n",
       " -0.009268530150184797,\n",
       " 0.00828120337731283,\n",
       " -0.0005372446283700639,\n",
       " -0.01378555008950792,\n",
       " -0.00042385630329094126,\n",
       " 0.020474690046736514,\n",
       " 0.02544834771047337,\n",
       " -0.008608255009939154,\n",
       " 0.029323605340561977,\n",
       " 0.0019299153682869883,\n",
       " 0.00700384923685286,\n",
       " 0.013871941438247937,\n",
       " 0.015550397138394807,\n",
       " -0.019006040843446696,\n",
       " -0.013908966168947571,\n",
       " 0.0008507980202094065,\n",
       " 0.0077381738384977704,\n",
       " -0.0015241857172626336,\n",
       " -0.005035366634779299,\n",
       " -0.030113467503917645,\n",
       " -0.022288902782341167,\n",
       " 0.018290228141490294,\n",
       " 0.006368257871288718,\n",
       " -0.011255525583269484,\n",
       " 0.02474487689585772,\n",
       " -0.0009209907582300159,\n",
       " -0.031100794276789613,\n",
       " -0.021881629813322583,\n",
       " 0.006192390167634805,\n",
       " 0.023708184436267984,\n",
       " -0.009848584885360799,\n",
       " 0.01982058491883863,\n",
       " -0.01500736713391844,\n",
       " -0.015056733751958823,\n",
       " 0.0018928905211720278,\n",
       " -0.001351403485443908,\n",
       " 0.015476347676995541,\n",
       " -0.006173877802284988,\n",
       " 0.013254861972372302,\n",
       " 0.016895630262244977,\n",
       " 0.0015905217319045857,\n",
       " -0.0037641834379897056,\n",
       " -0.0018388961610401715,\n",
       " 0.005470407453330646,\n",
       " -0.008614425953609528,\n",
       " -0.010231174079697883,\n",
       " 0.0059085337437171795,\n",
       " 0.0107618621968335,\n",
       " -0.009953488133789323,\n",
       " -0.010009025695500082,\n",
       " 0.008811891494448446,\n",
       " -0.012526708314397767,\n",
       " 0.0216965052285018,\n",
       " 0.01569849512987072,\n",
       " -0.006905116466433402,\n",
       " -0.015636787555812205,\n",
       " -0.008756354864060305,\n",
       " -0.01059525044302384,\n",
       " 0.024016724169205802,\n",
       " -0.015846594052669256,\n",
       " 0.007830735665246854,\n",
       " 0.024473362824942155,\n",
       " 0.008892111899518088,\n",
       " 0.010212661248686757,\n",
       " -0.0024405483841551954,\n",
       " 0.017401634604699092,\n",
       " 0.017451000291416857,\n",
       " -0.0009410458594974264,\n",
       " 0.018549402187710343,\n",
       " -0.008466327030810995,\n",
       " 0.00017480698539907175,\n",
       " -0.013871941438247937,\n",
       " 0.0004894209790779284,\n",
       " -0.035198198428430784,\n",
       " -0.004973658595059474,\n",
       " -0.0005700269517116415,\n",
       " 0.023017055508993085,\n",
       " -0.020795569804369845,\n",
       " -0.007139606737971952,\n",
       " -0.010200319361346006,\n",
       " 0.01979590114415713,\n",
       " 0.017290559481277574,\n",
       " 0.020770887892333584,\n",
       " -0.018450668951629577,\n",
       " 0.00096032959280604,\n",
       " -0.007071728220243061,\n",
       " 0.0013274916607978404,\n",
       " 0.024658485547117703,\n",
       " -0.018018714070574728,\n",
       " -0.0011184560662382786,\n",
       " -0.005356247789396558,\n",
       " -0.009601752726481496,\n",
       " -0.014550728478182088,\n",
       " -0.0434917455557296,\n",
       " -0.004381262438204032,\n",
       " -0.0051649531922280155,\n",
       " -0.016796897026164208,\n",
       " -0.017981688408552476,\n",
       " -0.018796234346589644,\n",
       " 0.016105768098889306,\n",
       " 0.02009210085239943,\n",
       " 0.007287705660770485,\n",
       " -0.007670294855107569,\n",
       " -0.004618838181577769,\n",
       " -0.01963546219666308,\n",
       " 0.005991839620622009,\n",
       " 0.015932985401409274,\n",
       " 0.013193154398313787,\n",
       " 0.005967156311601818,\n",
       " -0.0212768922347877,\n",
       " 0.008065225936785405,\n",
       " -0.013884283325588689,\n",
       " -0.026065427176349007,\n",
       " 0.006954483084473786,\n",
       " 0.0034648998877267966,\n",
       " -0.002638013692163458,\n",
       " -0.01367447589740902,\n",
       " 0.0035605471863110675,\n",
       " 0.02143733304492698,\n",
       " -0.014970342403218805,\n",
       " -0.017796565686376928,\n",
       " 0.002671953183858558,\n",
       " 0.014020040361046471,\n",
       " 0.006139938543420542,\n",
       " 0.008460156087140621,\n",
       " -0.017660808650919145,\n",
       " 0.010440980576554931,\n",
       " -0.027793248563213642,\n",
       " 0.019314580576384514,\n",
       " 0.011625772890265817,\n",
       " -0.02715148718530174,\n",
       " 0.027497050717616572,\n",
       " 0.018191496768054764,\n",
       " 0.014970342403218805,\n",
       " 0.01097166869369055,\n",
       " -0.014451996173423938,\n",
       " -0.004217736621890868,\n",
       " -0.00484098656577557,\n",
       " 0.004301042498795698,\n",
       " 0.010021366651518215,\n",
       " -0.011348086944357258,\n",
       " -0.016118109986230058,\n",
       " -0.009478336647041846,\n",
       " -0.017006703523021256,\n",
       " 0.012125607220372177,\n",
       " -0.004507763989478869,\n",
       " -0.02094366872716838,\n",
       " 0.017413976492039844,\n",
       " 0.02621352609914754,\n",
       " -0.010768033140503876,\n",
       " -0.0016830836750689963,\n",
       " 0.007374097009510503,\n",
       " -0.012582245876108527,\n",
       " -0.014057065091746104,\n",
       " -0.027595783953697342,\n",
       " -0.021856946038641082,\n",
       " -0.015673813217834457,\n",
       " -0.019499703298560062,\n",
       " 0.027694515327132872,\n",
       " 0.01569849512987072,\n",
       " -0.005501261240359903,\n",
       " -0.04359047692916513,\n",
       " 0.0016352600257768608,\n",
       " -0.031347626435668914,\n",
       " -0.01368681778474977,\n",
       " -0.008429302300111362,\n",
       " 0.010391613958514548,\n",
       " -0.010132440843617115,\n",
       " -0.007676465798777945,\n",
       " -0.013908966168947571,\n",
       " 0.01277354047327707,\n",
       " 0.016722847564764942,\n",
       " 0.0015203289938839762,\n",
       " 0.00015764445576948603,\n",
       " -0.00958324082679299,\n",
       " -0.008034372149756146,\n",
       " -0.006220158948490185,\n",
       " 0.004372006488359777,\n",
       " -0.018203836792750276,\n",
       " -0.026040743401667503,\n",
       " -0.0006768587946601494,\n",
       " 0.003569803368985976,\n",
       " -0.04289934986453547,\n",
       " -0.015143124169376222,\n",
       " 0.012650124393837418,\n",
       " -0.01605640241217154,\n",
       " -0.014279213475943905,\n",
       " -0.004439885006088669,\n",
       " -0.008151616354202803,\n",
       " 0.007978834588045387,\n",
       " 0.020869619265769114,\n",
       " 0.01070632463512274,\n",
       " -0.01356340170531012,\n",
       " -0.01717948622050129,\n",
       " 0.01511844132601734,\n",
       " -0.024646145522422187,\n",
       " -0.004353494123009961,\n",
       " 0.0038444036102286932,\n",
       " 0.03517351837903976,\n",
       " -0.014711169288321372,\n",
       " 0.021523724393667,\n",
       " -0.009311725824554806,\n",
       " 9.32850278662032e-05,\n",
       " 0.014020040361046471,\n",
       " -0.01422984685790352,\n",
       " 0.01013861178728749,\n",
       " 0.001880548983077259,\n",
       " -0.00997200096480045,\n",
       " 0.008491009874169878,\n",
       " 0.0014146541446659999,\n",
       " 0.0042732737179403185,\n",
       " -0.02311578874507385,\n",
       " 0.03203875350029858,\n",
       " -0.025917328253550472,\n",
       " 0.012465000740339252,\n",
       " 0.015599762825112572,\n",
       " -0.013402960895170837,\n",
       " -0.00868230447133842,\n",
       " -0.013378278051811953,\n",
       " -0.0017864444204105819,\n",
       " -0.022659150089337502,\n",
       " -0.010403955845855298,\n",
       " -0.01959843653464083,\n",
       " -0.02455975417368217,\n",
       " -0.009811560154661165,\n",
       " 0.002150521249397849,\n",
       " 0.003915367832623427,\n",
       " -0.01727821945658206,\n",
       " 0.008287374320983204,\n",
       " -0.004868755346630949,\n",
       " -0.007701149107798137,\n",
       " 0.010885277344950532,\n",
       " -0.015550397138394807,\n",
       " 0.018031055957915477,\n",
       " -0.004615752709742581,\n",
       " -0.002420493282887785,\n",
       " 0.03137231021035042,\n",
       " -0.013699158740767903,\n",
       " -0.0061584509087703595,\n",
       " 0.01682158080084571,\n",
       " 0.005229746703783029,\n",
       " 0.012033044927961783,\n",
       " 0.015155466056716973,\n",
       " 0.23636602979807822,\n",
       " -0.0036592799567305265,\n",
       " -0.004489251624129053,\n",
       " 0.03147104158378595,\n",
       " 0.011965166410232892,\n",
       " 0.012458829796668876,\n",
       " 0.029126140731045677,\n",
       " 0.006584235311816143,\n",
       " 0.0072938766044408606,\n",
       " 0.023411986590670918,\n",
       " -0.003532778638286343,\n",
       " -0.02725021855873727,\n",
       " -0.03418618974352255,\n",
       " 0.014020040361046471,\n",
       " -0.009669631244210388,\n",
       " -0.004597240344392765,\n",
       " -0.03285329943833575,\n",
       " -0.002199887401776924,\n",
       " -0.010946985850331667,\n",
       " -0.02479424444522072,\n",
       " -0.011490015854808034,\n",
       " -0.01634025837042786,\n",
       " -0.01727821945658206,\n",
       " -0.00513101393336357,\n",
       " 0.024967025280055517,\n",
       " 0.03300139836113428,\n",
       " -0.01424218874524427,\n",
       " -0.005566054751914917,\n",
       " 0.020881961153109863,\n",
       " -0.011934312623203635,\n",
       " -0.0073926093748603195,\n",
       " -0.01205155775897291,\n",
       " 0.005174209607733579,\n",
       " 0.03337164380548538,\n",
       " 0.010712495578793117,\n",
       " 0.003211897483669084,\n",
       " 0.004282530133445882,\n",
       " 0.009435141903994457,\n",
       " -0.0008022030029584741,\n",
       " -0.0002634156968784801,\n",
       " 0.013637451166709386,\n",
       " 0.02702807017453947,\n",
       " -0.009793047323650038,\n",
       " -0.022042070623461866,\n",
       " -0.009379604342283698,\n",
       " -0.010755691253163124,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.embed_query(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51fc9dba-8318-45fd-850f-922cb3db1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed=embedding.embed_query(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aff6e60-24d6-4f00-87d1-b1aef3a01809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67b88bf-4810-4d0b-b185-400d8ed11b6a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from pinecone) (2024.8.30)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
      "  Using cached pinecone_plugin_assistant-1.7.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\asif\\appdata\\roaming\\python\\python312\\site-packages (from pinecone) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from pinecone) (2.2.2)\n",
      "Collecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asif\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\datascience\\anaconda\\envs\\asif\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.7)\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "Using cached pinecone_plugin_assistant-1.7.0-py3-none-any.whl (239 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, packaging, pinecone-plugin-assistant, pinecone\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "Successfully installed packaging-24.1 pinecone-7.3.0 pinecone-plugin-assistant-1.7.0 pinecone-plugin-interface-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script repl.exe is installed in 'E:\\DataScience\\anaconda\\envs\\asif\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires visions[type_image_path]==0.7.4, but you have visions 0.7.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd2fab-4a66-4000-af04-1439d7633b5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"name\": \"test\",\n",
      "    \"metric\": \"cosine\",\n",
      "    \"host\": \"test-yxyq80x.svc.aped-4627-b74a.pinecone.io\",\n",
      "    \"spec\": {\n",
      "        \"serverless\": {\n",
      "            \"cloud\": \"aws\",\n",
      "            \"region\": \"us-east-1\"\n",
      "        }\n",
      "    },\n",
      "    \"status\": {\n",
      "        \"ready\": true,\n",
      "        \"state\": \"Ready\"\n",
      "    },\n",
      "    \"vector_type\": \"dense\",\n",
      "    \"dimension\": 1536,\n",
      "    \"deletion_protection\": \"disabled\",\n",
      "    \"tags\": {\n",
      "        \"embedding_model\": \"text-embedding-3-small\"\n",
      "    }\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone,ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"\")\n",
    "index = pc.Index(\"test\")\n",
    "\n",
    "print(pc.list_indexes())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0ee46-b9f1-4efe-b1c7-8b0fc2d14e13",
   "metadata": {},
   "source": [
    "# Creating Embedding for each of the text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b678232-b2c1-41df-b480-14d158ebd522",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone\n",
      "  Downloading langchain_pinecone-0.2.11-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-pinecone) (0.3.68)\n",
      "Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (7.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-pinecone) (2.3.1)\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n",
      "  Downloading langchain_tests-0.3.20-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting langchain-openai>=0.3.11 (from langchain-pinecone)\n",
      "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting pytest-benchmark (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_benchmark-5.1.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pytest-codspeed (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_codspeed-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pytest-recording (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_recording-0.13.4-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting vcrpy>=7.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading vcrpy-7.0.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\n",
      "Requirement already satisfied: certifi in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.16.0)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.7.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.32.4)\n",
      "Collecting aiohttp>=3.9.0 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: colorama>=0.4 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.4.6)\n",
      "Collecting iniconfig>=1 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.19.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.4.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading multidict-6.6.3-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-openai>=0.3.11->langchain-pinecone) (1.95.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langchain-openai>=0.3.11->langchain-pinecone) (0.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain-pinecone) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain-pinecone) (0.10.0)\n",
      "Requirement already satisfied: sniffio in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain-pinecone) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain-pinecone) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.11->langchain-pinecone) (2024.11.6)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Collecting wrapt (from vcrpy>=7.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting py-cpuinfo (from pytest-benchmark->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: cffi>=1.17.1 in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.17.1)\n",
      "Collecting rich>=13.8.1 (from pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pycparser in e:\\datascience\\anaconda\\envs\\testopenai\\lib\\site-packages (from cffi>=1.17.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.22)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.8.1->pytest-codspeed->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading langchain_pinecone-0.2.11-py3-none-any.whl (23 kB)\n",
      "Downloading langchain_tests-0.3.20-py3-none-any.whl (46 kB)\n",
      "Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading pytest-8.4.1-py3-none-any.whl (365 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\n",
      "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading syrupy-4.9.1-py3-none-any.whl (52 kB)\n",
      "Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl (449 kB)\n",
      "Downloading multidict-6.6.3-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading vcrpy-7.0.0-py2.py3-none-any.whl (42 kB)\n",
      "Downloading pytest_benchmark-5.1.0-py3-none-any.whl (44 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pytest_codspeed-4.0.0-py3-none-any.whl (107 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pytest_recording-0.13.4-py3-none-any.whl (13 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Installing collected packages: py-cpuinfo, wrapt, propcache, pluggy, multidict, mdurl, iniconfig, frozenlist, aiohappyeyeballs, yarl, pytest, markdown-it-py, aiosignal, vcrpy, syrupy, rich, pytest-socket, pytest-benchmark, pytest-asyncio, aiohttp, pytest-recording, pytest-codspeed, aiohttp-retry, langchain-tests, langchain-openai, langchain-pinecone\n",
      "\n",
      "   ----------------------------------------  0/26 [py-cpuinfo]\n",
      "   ----------------------------------------  0/26 [py-cpuinfo]\n",
      "   - --------------------------------------  1/26 [wrapt]\n",
      "   - --------------------------------------  1/26 [wrapt]\n",
      "   ---- -----------------------------------  3/26 [pluggy]\n",
      "   ---- -----------------------------------  3/26 [pluggy]\n",
      "   ------ ---------------------------------  4/26 [multidict]\n",
      "   ------- --------------------------------  5/26 [mdurl]\n",
      "   --------- ------------------------------  6/26 [iniconfig]\n",
      "   ---------- -----------------------------  7/26 [frozenlist]\n",
      "   ------------ ---------------------------  8/26 [aiohappyeyeballs]\n",
      "   ------------- --------------------------  9/26 [yarl]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   --------------- ------------------------ 10/26 [pytest]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   ---------------- ----------------------- 11/26 [markdown-it-py]\n",
      "   -------------------- ------------------- 13/26 [vcrpy]\n",
      "   -------------------- ------------------- 13/26 [vcrpy]\n",
      "   -------------------- ------------------- 13/26 [vcrpy]\n",
      "   --------------------- ------------------ 14/26 [syrupy]\n",
      "   --------------------- ------------------ 14/26 [syrupy]\n",
      "   --------------------- ------------------ 14/26 [syrupy]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   ----------------------- ---------------- 15/26 [rich]\n",
      "   -------------------------- ------------- 17/26 [pytest-benchmark]\n",
      "   -------------------------- ------------- 17/26 [pytest-benchmark]\n",
      "   -------------------------- ------------- 17/26 [pytest-benchmark]\n",
      "   -------------------------- ------------- 17/26 [pytest-benchmark]\n",
      "   --------------------------- ------------ 18/26 [pytest-asyncio]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ----------------------------- ---------- 19/26 [aiohttp]\n",
      "   ------------------------------ --------- 20/26 [pytest-recording]\n",
      "   -------------------------------- ------- 21/26 [pytest-codspeed]\n",
      "   --------------------------------- ------ 22/26 [aiohttp-retry]\n",
      "   ----------------------------------- ---- 23/26 [langchain-tests]\n",
      "   ----------------------------------- ---- 23/26 [langchain-tests]\n",
      "   ----------------------------------- ---- 23/26 [langchain-tests]\n",
      "   ------------------------------------ --- 24/26 [langchain-openai]\n",
      "   ------------------------------------ --- 24/26 [langchain-openai]\n",
      "   -------------------------------------- - 25/26 [langchain-pinecone]\n",
      "   ---------------------------------------- 26/26 [langchain-pinecone]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiohttp-retry-2.9.1 aiosignal-1.4.0 frozenlist-1.7.0 iniconfig-2.1.0 langchain-openai-0.3.28 langchain-pinecone-0.2.11 langchain-tests-0.3.20 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.6.3 pluggy-1.6.0 propcache-0.3.2 py-cpuinfo-9.0.0 pytest-8.4.1 pytest-asyncio-0.26.0 pytest-benchmark-5.1.0 pytest-codspeed-4.0.0 pytest-recording-0.13.4 pytest-socket-0.7.0 rich-14.1.0 syrupy-4.9.1 vcrpy-7.0.0 wrapt-1.17.2 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44152c8-3362-41fd-9fd9-e93c93497e23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts py.test.exe and pytest.exe are installed in 'E:\\DataScience\\anaconda\\envs\\asif\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts py.test-benchmark.exe and pytest-benchmark.exe are installed in 'E:\\DataScience\\anaconda\\envs\\asif\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6448b147-aea3-4c84-891e-9c35ddc9b9d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Pinecone as LangchainPinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876f6d7-c464-43c1-9135-bd02663a6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Set env variable for LangChain\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
    "\n",
    "# Init Pinecone v4\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "if \"test\" not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=\"test\",\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "# Create vector store from texts\n",
    "docsearch = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks],\n",
    "    embedding,\n",
    "    index_name=\"test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd38f45c-aaa8-4609-9331-04dc08a052fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x1ebc6295ee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dae2740-16bf-4557-911e-c44a14f422bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Transformer architechure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "840e08f3-e3ff-441e-9cfc-2267851434b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "770b97cb-2736-4d98-8d85-c1a55631c78b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c32490be-e0c2-4f76-95fd-1bccebe0e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36a50a77-5f19-474e-9681-464e6714a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c05c399-a59d-49e3-a1ef-16327706d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is Transformer architechure?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1336e43d-3707-4350-826f-c0e437b2b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Transformer is a model architecture that uses stacked self-attention and point-wise, fully connected layers for both the encoder and decoder. It is composed of a stack of identical layers, each with two sub-layers - a multi-head self-attention mechanism and a simple, position-independent feed-forward network. It is the first transduction model to rely entirely on self-attention, without using sequence-aligned RNNs or convolution. '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d97f6-f8c1-4f23-aaef-ab1161c87f43",
   "metadata": {},
   "source": [
    "# Small QA system from given pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f9c3bd7-437d-4498-9cae-8355c347fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Prompt :  what is transformer?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer :  The Transformer is a sequence transduction model that uses self-attention instead of recurrent layers or convolution to compute representations of input and output. It is designed to significantly reduce sequential computation and has shown to achieve state-of-the-art results in translation tasks with faster training times compared to other architectures.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Prompt :  how transformer dominate other models?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer :  \n",
      "The Transformer dominates other models due to its simplicity and use of attention mechanisms, rather than complex recurrent or convolutional neural networks. It also outperforms other models, such as the ones mentioned in context, and does so at a much lower training cost. Additionally, the Transformer is able to achieve high performance by using a single model, whereas other models require multiple models to achieve similar results.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Prompt :  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "while True:\n",
    "    user_input=input(f\"Input Prompt : \")\n",
    "    if user_input==\"exit\":\n",
    "        print(\"Existing\")\n",
    "        break\n",
    "    if user_input==\"\":\n",
    "        continue\n",
    "    result=qa({\"query\":user_input})\n",
    "    print(f\"Answer : {result['result']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4a7e9-3d08-4a12-8678-5a3bc8551cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1",
   "language": "python",
   "name": "python3.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
